{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8e17830-683b-414a-9608-30457857072b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv('/FileStore/tables/heart_attack_prediction_dataset.csv', header=True, inferSchema=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55d9d425-6889-44dd-869f-506d6c7e4479",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split\n",
    "df = df.withColumn(\"Pressao_Sistolica\", split(df[\"Blood Pressure\"], \"/\")[0].cast(\"int\"))\n",
    "df = df.withColumn(\"Pressao_Diastolica\", split(df[\"Blood Pressure\"], \"/\")[1].cast(\"int\"))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3792cb8-e69b-4467-93e2-9bc65a295146",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df_zero = df.filter(col('Heart Attack Risk') == 0)\n",
    "df_um = df.filter(col('Heart Attack Risk') == 1)\n",
    "amostra_zeros = df_zero.sample(False, 1.0).distinct().limit(3139)\n",
    "df = amostra_zeros.union(df_um)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7160204f-2037-4040-bd0d-83352a2c2241",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "\n",
    "feature_columns = [\n",
    "    'Age', 'Cholesterol', \n",
    "    'Heart Rate', 'Diabetes', 'Family History', 'Smoking', 'Obesity', \n",
    "    'Alcohol Consumption', 'Exercise Hours Per Week', \n",
    "    'Previous Heart Problems', 'Medication Use', 'Stress Level', \n",
    "    'Sedentary Hours Per Day', 'Income', 'BMI', 'Triglycerides', \n",
    "    'Physical Activity Days Per Week', 'Sleep Hours Per Day', 'Pressao_Sistolica','Pressao_Diastolica'\n",
    "]\n",
    "\n",
    "# Colunas categóricas a serem convertidas\n",
    "string_columns = ['Sex','Diet','Blood Pressure']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#feature_columns = ['Physical Activity Days Per Week','Medication Use','Previous Heart Problems',\n",
    " #                   'Stress Level','Smoking','Age']\n",
    "\n",
    "# Colunas categóricas a serem convertidas\n",
    "#string_columns = ['Sex','Diet', 'Blood Pressure']\n",
    "\n",
    "\n",
    "\n",
    "# Criando um StringIndexer para cada coluna categórica\n",
    "#indexers = [StringIndexer(inputCol=column, outputCol=column + \"_index\", handleInvalid=\"keep\") for column in string_columns]\n",
    "\n",
    "vec_assembler = VectorAssembler(inputCols=feature_columns, outputCol='features')\n",
    "\n",
    "df_transform = vec_assembler.transform(df)\n",
    "df_transform.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8f7ad7e-1b60-4442-99c7-247fa9638908",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_train, df_test = df_transform.randomSplit([.8, .2], seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e81ad046-5abd-4705-bd54-fa695e56a81f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(maxDepth=5, labelCol='Heart Attack Risk', featuresCol='features')\n",
    "\n",
    "#ajustando aos dados de treino\n",
    "rf_model = rf.fit(df_train)\n",
    "\n",
    "#vendo tamanho da árvorer\n",
    "tree_structure = rf_model.toDebugString\n",
    "\n",
    "# Divida a string em linhas e conte as linhas\n",
    "num_nodes = len(tree_structure.split('\\n'))\n",
    "\n",
    "# Exiba o número de nós\n",
    "print(f\"Número total de nós na árvore: {num_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e43be15d-930d-4295-97df-617a34fc74ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_pred = rf_model.transform(df_test)\n",
    "df_pred = df_pred.withColumnRenamed('prediction','prediction_RF')\n",
    "df_pred.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a84aedd9-89cd-4cf7-809b-5cda6013956a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Adicionar coluna com a diferença entre a previsão e o rótulo real\n",
    "df_comparison = df_pred.withColumn(\"prediction_diff\", col(\"prediction_RF\") - col(\"Heart Attack Risk\"))\n",
    "\n",
    "\n",
    "# Contar o número de acertos e erros\n",
    "correct_predictions = df_comparison.filter(col(\"prediction_diff\") == 0).count()\n",
    "incorrect_predictions = df_comparison.filter(col(\"prediction_diff\") != 0).count()\n",
    "\n",
    "# Calcular a acurácia\n",
    "total_predictions = df_comparison.count()\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "# Exibir os resultados\n",
    "print(f\"Total de Previsões: {total_predictions}\")\n",
    "print(f\"Número de Acertos: {correct_predictions}\")\n",
    "print(f\"Número de Erros: {incorrect_predictions}\")\n",
    "print(f\"Acurácia: {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4dda2aed-17b0-42e8-bce3-838b42abbf75",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_pred.filter(df_pred['prediction_RF']==1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5df61a2c-bc13-4645-a797-ce1ac681aaa4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_test)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "decision tree sem encoder",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
